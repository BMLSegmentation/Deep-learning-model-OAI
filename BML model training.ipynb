{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtjfoPL55CnM2tEO45r+0n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vj_8rNla35I3"},"outputs":[],"source":["# Installing libraries\n","!pip install segmentation-models==1.0.1\n","!pip install tensorflow\n","!pip install h5py\n","!pip install SimpleITK"]},{"cell_type":"code","source":["# Importing libraries\n","%matplotlib inline\n","import glob\n","import cv2\n","import random\n","import os\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","%env SM_FRAMEWORK=tf.keras\n","import segmentation_models as sm\n","import pandas as pd\n","import imageio\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","from scipy.stats import sem, t\n","from numpy import mean\n","from tensorflow.keras.layers import Input\n","from keras.models import Model\n","import scipy.stats as stats\n","from keras.layers import Average\n","from keras.utils import to_categorical"],"metadata":{"id":"A_milCpq4JPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mounting google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"V5ttFyZq4P9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Loading images and masks for the BML model (Model 3)\n","\n","mask_dir = '/content/drive/MyDrive/BML_Masks'\n","img_dir = '/content/drive/MyDrive/BML_Images'\n","\n","# Initialize lists to store the medial and lateral images and masks\n","img_list = []\n","mask_list = []\n","\n","# Initialize a list to store image names\n","image_names = []\n","\n","# Sort the subject subfolders in each directory\n","img_subjects = sorted(os.listdir(img_dir))\n","mask_subjects = sorted(os.listdir(mask_dir))\n","\n","# Loop over the subject subfolders in the image directory\n","for subject_id in img_subjects:\n","    # Set the path to the subject's subfolder\n","    subject_img_dir = os.path.join(img_dir, subject_id)\n","\n","    # Get a list of image files in the subject's subfolder\n","    img_files = [f for f in os.listdir(subject_img_dir) if f.endswith('.tif')]\n","\n","    # Sort the image files by their slice number\n","    img_files.sort(key=lambda x: int(x.split('.')[0]))\n","\n","    # Loop over the sorted image files\n","    for img_file in img_files:\n","        # Set the path to the image file\n","        img_path = os.path.join(subject_img_dir, img_file)\n","\n","        # Load the image using imageio\n","        img = imageio.v2.imread(img_path)\n","        slice_number = int(img_file.split('.')[0])\n","\n","        #image padding\n","        pad_height = 448 - img.shape[0]\n","        pad_width = 448 - img.shape[1]\n","        # Apply padding to height and width\n","        padding = ((0, pad_height), (0, pad_width))\n","        img = np.pad(img, padding, mode='constant', constant_values=0)\n","        image_name = f\"{subject_id}_{slice_number}\"\n","        # Add image name to list\n","        image_names.append(image_name)\n","\n","\n","        # Add the image to the medial image list\n","        img_list.append(img)\n","\n","# Convert the image lists to numpy arrays\n","img_array = np.array(img_list)\n","image_names = np.array(image_names)\n","\n","# Loop over the subject subfolders in the mask directory\n","for subject_id in mask_subjects:\n","    # Set the path to the subject's subfolder\n","    subject_mask_dir = os.path.join(mask_dir, subject_id)\n","\n","    # Get a list of mask files in the subject's subfolder\n","    mask_files = [f for f in os.listdir(subject_mask_dir) if f.endswith('.tif')]\n","\n","    # Sort the mask files by their slice number\n","    mask_files.sort(key=lambda x: int(x.split('.')[0]))\n","\n","    # Loop over the sorted mask files\n","    for mask_file in mask_files:\n","        # Set the path to the mask file\n","        mask_path = os.path.join(subject_mask_dir, mask_file)\n","\n","        # Load the mask using imageio\n","        mask = imageio.v2.imread(mask_path)\n","\n","        # Check if the slice number is less than 16 or greater than 18\n","        slice_number = int(mask_file.split('.')[0])\n","        #image padding\n","        pad_height = 448 - mask.shape[0]\n","        pad_width = 448 - mask.shape[1]\n","        # Apply padding to height and width\n","        padding = ((0, pad_height), (0, pad_width))\n","        mask = np.pad(mask, padding, mode='constant', constant_values=0)\n","\n","        # Add the mask to the medial mask list\n","        mask_list.append(mask)\n","\n","# Convert the mask list to numpy array\n","mask_array = np.array(mask_list)"],"metadata":{"id":"LG_AL-bk4o3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoding labels for combined BML masks\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder = LabelEncoder()\n","n, h, w = mask_array.shape\n","train_masks_reshaped = mask_array.reshape(-1,1)\n","train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n","train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n","print(train_masks_encoded_original_shape.shape)\n","print(train_masks_reshaped_encoded.shape)\n","np.unique(train_masks_encoded_original_shape)"],"metadata":{"id":"yn5qvNp_jciU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adding a dimension to masks to match images (Read in RGB)\n","train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)\n","\n","# Reformating classes\n","n_classes = 2\n","train_masks_cat = to_categorical(train_masks_input, num_classes=n_classes)\n","masks_cat = train_masks_cat.reshape((train_masks_input.shape[0], train_masks_input.shape[1], train_masks_input.shape[2], n_classes))"],"metadata":{"id":"ibGY-_9sjKLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a learning rate schedule\n","def scheduler(epoch, lr):\n","    if epoch < 50:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","# Create a callback for the learning rate scheduler\n","callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"],"metadata":{"id":"hlg6XrWEe2-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#---------------kfold cross validation the model-------------------\n","\n","\n","# Define the number of folds\n","n_folds = 5\n","\n","# Define the dice coefficient function\n","def dice_coefficient(y_true, y_pred):\n","    intersection = np.sum(y_true * y_pred, axis=(1, 2))\n","    union = np.sum(y_true, axis=(1, 2)) + np.sum(y_pred, axis=(1, 2))\n","    dice = 2. * intersection / union\n","    return dice\n","\n","# Initialize the cross-validation object\n","kf = KFold(n_splits=n_folds)\n","\n","# Initialize a list to store the history of each fold\n","models = []\n","\n","# Loop over each fold\n","for fold, (train_index, val_index) in enumerate(kf.split(img_array_rgb)):\n","    # Split the data\n","    X_train, X_val = img_array_rgb[train_index], img_array_rgb[val_index]\n","    y_train, y_val = masks_cat[train_index], masks_cat[val_index]\n","\n","    #Define BML_fold model\n","    activation='softmax'\n","    LR = 0.0001\n","    optim = tf.keras.optimizers.Adam(LR)\n","    total_loss = sm.losses.DiceLoss()\n","    metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy']\n","    BACKBONE = 'resnet50'\n","    preprocess_input = sm.get_preprocessing(BACKBONE)\n","    X_train = preprocess_input(X_train)\n","    X_val = preprocess_input(X_val)\n","    BMLmodel_fold = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=n_classes, activation=activation, decoder_use_batchnorm=True)\n","    BMLmodel_fold.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n","\n","    # Fit the model\n","    history = BMLmodel_fold.fit(X_train,\n","                           y_train,\n","                           batch_size=8,\n","                           epochs=100,\n","                           verbose=1,\n","                           validation_data=(X_val, y_val),\n","                           callbacks=[callback])\n","\n","\n","    # Add the trained model to the list\n","    models.append(BMLmodel_fold)\n","\n","# Create an ensemble model from the 5 models\n","ensemble_inputs = Input(shape=img_array_rgb.shape[1:])\n","ensemble_outputs = Average()([model(ensemble_inputs) for model in models])\n","ensemble_model = Model(inputs=ensemble_inputs, outputs=ensemble_outputs)\n","\n","# Make predictions on the entire dataset with the ensemble model\n","y_pred_ensemble = ensemble_model.predict(img_array_rgb)\n","\n","# Calculate the Dice score and AUC for the ensemble model\n","dice_scores_ensemble = dice_coefficient(masks_cat[..., 1], y_pred_ensemble[..., 1])\n","mean_dice_ensemble = np.mean(dice_scores_ensemble)\n","confidence_interval_dice_ensemble = stats.t.interval(0.95, len(dice_scores_ensemble)-1, loc=mean_dice_ensemble, scale=stats.sem(dice_scores_ensemble))\n","\n","auc_scores_ensemble = [roc_auc_score(masks_cat[i, ..., 1].flatten(), y_pred_ensemble[i, ..., 1].flatten()) for i in range(masks_cat.shape[0])]\n","mean_auc_ensemble = np.mean(auc_scores_ensemble)\n","confidence_interval_auc_ensemble = stats.t.interval(0.95, len(auc_scores_ensemble)-1, loc=mean_auc_ensemble, scale=stats.sem(auc_scores_ensemble))\n","\n","# Calculate and print the Dice score and AUC for the ensemble model\n","print(\"Ensemble model Dice score: \", mean_dice_ensemble)\n","print(\"Ensemble model 95% confidence interval for Dice score: \", confidence_interval_dice_ensemble)\n","print(\"Ensemble model AUC: \", mean_auc_ensemble)\n","print(\"Ensemble model 95% confidence interval for AUC: \", confidence_interval_auc_ensemble)"],"metadata":{"id":"XJLid7PlfJ_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving the model\n","model.save('/content/drive/MyDrive/BML_segmentation/BMLmodel.h5')"],"metadata":{"id":"VDV-8Hpzs6QK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------leave one center out cross validation model-----------------------\n","\n","# Define the dice coefficient function\n","def dice_coefficient(y_true, y_pred):\n","    intersection = np.sum(y_true * y_pred, axis=(1, 2))\n","    union = np.sum(y_true, axis=(1, 2)) + np.sum(y_pred, axis=(1, 2))\n","    dice = 2. * intersection / union\n","    return dice\n","\n","# Initialize lists to store the Dice scores, AUCs, and models for each center\n","dice_scores = []\n","aucs = []\n","models = []\n","\n","center_names = ['A', 'B', 'C', 'D', 'E']  # Define your center names\n","\n","for center in center_names:\n","    # Create a boolean mask for the current center\n","    train_mask = [name.split('_')[1] != center for name in names]\n","    test_mask = [name.split('_')[1] == center for name in names]\n","\n","    # Apply the mask to get the train and test sets for the current center\n","    X_train_center = img_array_rgb[train_mask]\n","    y_train_center = masks_cat[train_mask]\n","    X_test_center = img_array_rgb[test_mask]\n","    y_test_center = masks_cat[test_mask]\n","\n","    # Clone the base model for the current center\n","    activation='softmax'\n","    LR = 0.0001\n","    optim = tf.keras.optimizers.Adam(LR)\n","    total_loss = sm.losses.DiceLoss()\n","    metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy']\n","    BACKBONE = 'resnet50'\n","    preprocess_input = sm.get_preprocessing(BACKBONE)\n","    X_train_center = preprocess_input(X_train_center)\n","    X_test_center = preprocess_input(X_test_center)\n","    BMLmodel_center = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=n_classes, activation=activation, decoder_use_batchnorm=True)\n","    BMLmodel_center.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n","\n","    # Fit the model for the current center\n","    history = BMLmodel_center.fit(X_train_center,\n","                                  y_train_center,\n","                                  batch_size=8,\n","                                  epochs=100,\n","                                  verbose=1,\n","                                  validation_data=(X_test_center, y_test_center),callbacks=[callback])\n","\n","    # Add the trained model to the list\n","    models.append(BMLmodel_center)\n","\n","# Create an ensemble model from the 5 models\n","ensemble_inputs = Input(shape=img_array_rgb.shape[1:])\n","ensemble_outputs = Average()([model(ensemble_inputs) for model in models])\n","ensemble_model = Model(inputs=ensemble_inputs, outputs=ensemble_outputs)\n","\n","# Make predictions on the entire dataset with the ensemble model\n","y_pred_ensemble = ensemble_model.predict(img_array_rgb)\n","\n","# Calculate the Dice score and AUC for the ensemble model\n","dice_scores_ensemble = dice_coefficient(masks_cat[..., 1], y_pred_ensemble[..., 1])\n","mean_dice_ensemble = np.mean(dice_scores_ensemble)\n","confidence_interval_dice_ensemble = stats.t.interval(0.95, len(dice_scores_ensemble)-1, loc=mean_dice_ensemble, scale=stats.sem(dice_scores_ensemble))\n","\n","auc_scores_ensemble = [roc_auc_score(masks_cat[i, ..., 1].flatten(), y_pred_ensemble[i, ..., 1].flatten()) for i in range(masks_cat.shape[0])]\n","mean_auc_ensemble = np.mean(auc_scores_ensemble)\n","confidence_interval_auc_ensemble = stats.t.interval(0.95, len(auc_scores_ensemble)-1, loc=mean_auc_ensemble, scale=stats.sem(auc_scores_ensemble))\n","\n","# Calculate and print the Dice score and AUC for the ensemble model\n","print(\"Ensemble model Dice score: \", mean_dice_ensemble)\n","print(\"Ensemble model 95% confidence interval for Dice score: \", confidence_interval_dice_ensemble)\n","print(\"Ensemble model AUC: \", mean_auc_ensemble)\n","print(\"Ensemble model 95% confidence interval for AUC: \", confidence_interval_auc_ensemble)"],"metadata":{"id":"TsmlObI_4sTd"},"execution_count":null,"outputs":[]}]}